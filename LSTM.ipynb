{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNblgFEtOKFUTyLsqeiK9tv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuvashuvs/Distributed_Generation_Event_Classification_LSTM/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkUiR1VLITcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8M8Kfg5IsvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('myDataFile.csv',header=None)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WcGtY-WJDXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07gu_o6RJER_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df.iloc[:,:9]\n",
        "y = df.iloc[:,9:10]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGZ6lYw5Jj3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "216421c5-e92d-4e46-a0b5-334222c504dc"
      },
      "source": [
        "# x=x.iloc[0:10].values\n",
        "# y=y.iloc[0:10]\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             0         1         2         3  ...       5        6       7        8\n",
            "0     -0.19059 -1.902800  15.29500 -0.500090  ...  60.002  0.99736  3.3040  0.98770\n",
            "1     -1.09010 -3.296400  20.28600 -1.558500  ...  59.984  0.99965  1.3854  0.96180\n",
            "2      0.14129  1.129000  -3.60000 -0.669790  ...  59.987  0.99924  1.1090  0.95073\n",
            "3      0.43103  1.185200   0.14178  1.891200  ...  59.994  0.99926  1.2978  0.98215\n",
            "4      0.72313 -0.069471   1.03700  0.457150  ...  60.006  0.99938  1.2777  0.98971\n",
            "...        ...       ...       ...       ...  ...     ...      ...     ...      ...\n",
            "10995 -1.52030  3.099100   2.23730  7.702000  ...  59.985  0.99572  1.0750  0.96373\n",
            "10996  0.77303 -1.691700  -3.63550  0.735900  ...  59.997  0.99531  1.3409  0.97557\n",
            "10997  0.18220 -0.736770  -0.37476 -0.611240  ...  60.000  0.99527  1.1978  0.96542\n",
            "10998 -0.38011  0.055299   1.01850  0.421260  ...  59.994  0.99538  1.1210  0.97251\n",
            "10999 -0.11994  2.264600   0.66754 -0.030873  ...  59.992  0.99546  1.1138  0.97198\n",
            "\n",
            "[11000 rows x 9 columns]\n",
            "       9\n",
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "...   ..\n",
            "10995  9\n",
            "10996  9\n",
            "10997  9\n",
            "10998  9\n",
            "10999  9\n",
            "\n",
            "[11000 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxRQs94qJksC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################\n",
        "# Functions\n",
        "######################################################################################################\n",
        "def create_dataset(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(0,len(X) - time_steps,time_steps):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        Xs.append(v)\n",
        "        ys.append(y.iloc[i + time_steps].values)\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "def create_sub_dataset(X, y, time_steps=1):\n",
        "    Xs = []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        Xs.append(v)\n",
        "    return np.array(Xs)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBfQ9XZVJzhZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3de6e7d-adc4-4e64-b250-c918e6ba2937"
      },
      "source": [
        "X,Y = create_dataset(x,y,10)\n",
        "print(X.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1099, 10, 9)\n",
            "[[[-1.9059e-01 -1.9028e+00  1.5295e+01 ...  9.9736e-01  3.3040e+00\n",
            "    9.8770e-01]\n",
            "  [-1.0901e+00 -3.2964e+00  2.0286e+01 ...  9.9965e-01  1.3854e+00\n",
            "    9.6180e-01]\n",
            "  [ 1.4129e-01  1.1290e+00 -3.6000e+00 ...  9.9924e-01  1.1090e+00\n",
            "    9.5073e-01]\n",
            "  ...\n",
            "  [-6.8260e-02 -4.6969e+00  3.4488e+00 ...  9.9931e-01  1.1664e+00\n",
            "    9.4203e-01]\n",
            "  [-1.0136e-01  2.7443e+00  1.1135e-01 ...  9.9932e-01  1.2963e+00\n",
            "    9.6978e-01]\n",
            "  [ 3.7899e-01  1.8249e+00  2.7467e-01 ...  9.9936e-01  1.2043e+00\n",
            "    9.7897e-01]]\n",
            "\n",
            " [[-2.5916e-02  3.4562e+00  1.9622e+01 ...  9.9757e-01  3.8161e+00\n",
            "    9.9051e-01]\n",
            "  [-1.1129e+00 -2.2936e+00  2.4837e+01 ...  1.0004e+00  1.5330e+00\n",
            "    9.8674e-01]\n",
            "  [ 2.1980e-01 -4.0292e+00 -5.3422e+00 ...  9.9978e-01  8.5241e-01\n",
            "    9.9120e-01]\n",
            "  ...\n",
            "  [-3.6056e-01 -5.8827e-01  1.5013e+00 ...  1.0000e+00  1.2191e+00\n",
            "    9.5773e-01]\n",
            "  [ 2.0256e-01  6.6196e-01  7.1341e-01 ...  1.0001e+00  1.3463e+00\n",
            "    9.4294e-01]\n",
            "  [ 7.1773e-02  7.1578e-01 -7.4109e-01 ...  9.9999e-01  9.5115e-01\n",
            "    9.4065e-01]]\n",
            "\n",
            " [[-4.1042e-01  3.5160e+00  1.8564e+01 ...  9.9770e-01  4.2630e+00\n",
            "    9.8088e-01]\n",
            "  [ 1.5576e-01 -5.2112e+00  3.2532e+01 ...  1.0014e+00  1.8854e+00\n",
            "    9.7213e-01]\n",
            "  [-6.8972e-01 -2.0251e+00 -6.6817e+00 ...  1.0006e+00  1.3144e+00\n",
            "    9.4063e-01]\n",
            "  ...\n",
            "  [-2.9725e-02 -1.4866e+00  1.5278e-02 ...  1.0005e+00  1.1044e+00\n",
            "    9.7321e-01]\n",
            "  [ 2.3363e-01  1.8764e+00  9.4432e-01 ...  1.0006e+00  1.4296e+00\n",
            "    9.8866e-01]\n",
            "  [ 1.4697e-01 -1.1027e+00 -4.4797e-01 ...  1.0005e+00  1.2928e+00\n",
            "    9.9033e-01]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 5.0245e-02  3.1860e+01 -2.3821e+02 ...  9.6805e-01  2.8037e+01\n",
            "    7.6643e-01]\n",
            "  [-2.7366e-02  3.2094e+01  2.3193e+02 ...  9.9465e-01  9.8225e+00\n",
            "    2.2079e-01]\n",
            "  [ 1.4578e+00 -7.3040e+01  4.1085e+00 ...  9.9498e-01  1.4678e+00\n",
            "   -2.4834e-01]\n",
            "  ...\n",
            "  [ 1.4087e-01 -1.0315e+01 -1.5657e+00 ...  9.9536e-01  1.1716e+00\n",
            "    9.7733e-01]\n",
            "  [ 4.6813e-01  9.2339e+00  1.5390e+00 ...  9.9553e-01  1.2518e+00\n",
            "    9.9453e-01]\n",
            "  [ 3.5443e-01  1.9256e+00 -1.0417e+00 ...  9.9541e-01  1.5228e+00\n",
            "    9.9141e-01]]\n",
            "\n",
            " [[ 5.4286e-02  2.7365e+01 -2.2516e+02 ...  9.6954e-01  2.7769e+01\n",
            "    8.4270e-01]\n",
            "  [ 6.8783e-02  2.5560e+01  2.2124e+02 ...  9.9491e-01  9.8746e+00\n",
            "    3.3073e-01]\n",
            "  [ 1.6375e+00 -6.1328e+01 -6.4509e-01 ...  9.9476e-01  1.1613e+00\n",
            "   -2.0828e-01]\n",
            "  ...\n",
            "  [-1.6983e-01 -1.0324e+01 -2.0116e+00 ...  9.9517e-01  1.2016e+00\n",
            "    9.0304e-01]\n",
            "  [ 1.2115e-01  6.1121e+00  3.1710e+00 ...  9.9553e-01  1.4872e+00\n",
            "    9.4759e-01]\n",
            "  [ 2.9824e-01  3.3985e+00 -1.7567e+00 ...  9.9532e-01  1.3624e+00\n",
            "    9.8538e-01]]\n",
            "\n",
            " [[ 4.8860e-02  2.6461e+01 -2.2376e+02 ...  9.6970e-01  2.7278e+01\n",
            "    8.2643e-01]\n",
            "  [ 1.5657e-03  2.5970e+01  2.1923e+02 ...  9.9484e-01  9.5153e+00\n",
            "    3.0688e-01]\n",
            "  [ 1.6372e+00 -5.7299e+01 -9.6801e-02 ...  9.9467e-01  1.1125e+00\n",
            "   -1.8465e-01]\n",
            "  ...\n",
            "  [-1.6596e-01 -2.3809e+00  1.3417e+00 ...  9.9552e-01  1.2471e+00\n",
            "    9.3908e-01]\n",
            "  [ 2.2329e-01  2.3870e+00 -3.3360e-01 ...  9.9548e-01  1.3921e+00\n",
            "    9.8727e-01]\n",
            "  [ 3.4261e-01 -8.9508e-01  8.9384e-01 ...  9.9559e-01  1.3145e+00\n",
            "    9.8266e-01]]]\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [9]\n",
            " [9]\n",
            " [9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uIgID5aLcE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCw6MNfkFBJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is1_0uanPAbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################\n",
        "# Preprocessing\n",
        "######################################################################################################\n",
        "# train test splitting\n",
        "train_size = int(len(X) * 0.70)\n",
        "X_train, X_test = X[0:train_size], X[train_size:len(x)]\n",
        "y_train, y_test = Y[0:train_size], Y[train_size:len(x)]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp_yY530J85E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fd7830e-d8c0-4508-af28-e4050ecef8b3"
      },
      "source": [
        "TIME_STEPS = 10\n",
        "\n",
        "print(X_train.shape)\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(769, 10, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K09DalCU0GF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "6e3d3d64-ef70-4860-9dc8-e1ae7e9ec9e3"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "encoded_y_train = encoder.transform(y_train)\n",
        "encoded_y_test = encoder.transform(y_test)\n",
        "\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "one_hot_y_train = np_utils.to_categorical(encoded_y_train)\n",
        "one_hot_y_test = np_utils.to_categorical(encoded_y_test)\n",
        "print(one_hot_y_train)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3TgK50iKxrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7eabf0e7-5091-41c4-911a-9a1af50537ce"
      },
      "source": [
        "######################################################################################################\n",
        "# Model building\n",
        "######################################################################################################\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.LSTM(100,input_shape=(TIME_STEPS,X_train.shape[2])))\n",
        "# model.add(keras.layers.Dropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(11, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "history = model.fit(X_train,one_hot_y_train, validation_data=(X_test,one_hot_y_test), epochs=300, batch_size=10000,shuffle = True,callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n",
        "# history = model.fit(X_train,one_hot_y_train, validation_data=(X_test,one_hot_y_test), epochs=50, batch_size=64,shuffle = False)\n",
        "\n",
        "# predictions\n",
        "test_pred = model.predict(X_test)\n",
        "predicted = np.argmax(test_pred, axis=1)\n",
        "print(predicted.shape)\n",
        "print(predicted)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.5250 - val_loss: 2.4917\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.4769 - val_loss: 2.4462\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.4313 - val_loss: 2.4038\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3884 - val_loss: 2.3647\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3485 - val_loss: 2.3291\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.3125 - val_loss: 2.2969\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2806 - val_loss: 2.2684\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2525 - val_loss: 2.2419\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2264 - val_loss: 2.2161\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2004 - val_loss: 2.1906\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1743 - val_loss: 2.1655\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1482 - val_loss: 2.1408\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1226 - val_loss: 2.1163\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.0975 - val_loss: 2.0924\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.0730 - val_loss: 2.0685\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.0490 - val_loss: 2.0446\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.0251 - val_loss: 2.0213\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.0012 - val_loss: 1.9981\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1.9773 - val_loss: 1.9747\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1.9533 - val_loss: 1.9509\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.9289 - val_loss: 1.9270\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1.9041 - val_loss: 1.9027\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 1.8789 - val_loss: 1.8780\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 1.8532 - val_loss: 1.8535\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.8270 - val_loss: 1.8287\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.8006 - val_loss: 1.8035\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.7739 - val_loss: 1.7781\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.7464 - val_loss: 1.7524\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.7184 - val_loss: 1.7259\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.6893 - val_loss: 1.6983\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.6589 - val_loss: 1.6691\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.6270 - val_loss: 1.6383\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.5936 - val_loss: 1.6062\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.5582 - val_loss: 1.5729\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.5214 - val_loss: 1.5384\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.4833 - val_loss: 1.5030\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.4440 - val_loss: 1.4665\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.4034 - val_loss: 1.4284\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.3616 - val_loss: 1.3892\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.3184 - val_loss: 1.3485\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.2740 - val_loss: 1.3057\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.2288 - val_loss: 1.2615\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1.1824 - val_loss: 1.2171\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.1358 - val_loss: 1.1727\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.0892 - val_loss: 1.1293\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.0428 - val_loss: 1.0859\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.9965 - val_loss: 1.0428\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.9500 - val_loss: 1.0009\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.9044 - val_loss: 0.9594\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.8594 - val_loss: 0.9178\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.8148 - val_loss: 0.8754\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.7700 - val_loss: 0.8341\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.7255 - val_loss: 0.7931\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6814 - val_loss: 0.7535\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6383 - val_loss: 0.7166\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5973 - val_loss: 0.6816\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5578 - val_loss: 0.6479\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.5201 - val_loss: 0.6154\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.4842 - val_loss: 0.5859\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.4512 - val_loss: 0.5596\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.4209 - val_loss: 0.5348\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3930 - val_loss: 0.5114\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3667 - val_loss: 0.4902\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.3418 - val_loss: 0.4711\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.3187 - val_loss: 0.4550\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.3000 - val_loss: 0.4407\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2826 - val_loss: 0.4269\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.2662 - val_loss: 0.4139\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2522 - val_loss: 0.4009\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.2396 - val_loss: 0.3888\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.2283 - val_loss: 0.3781\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.2177 - val_loss: 0.3688\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2080 - val_loss: 0.3607\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1994 - val_loss: 0.3526\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1915 - val_loss: 0.3447\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1841 - val_loss: 0.3370\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1772 - val_loss: 0.3301\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1708 - val_loss: 0.3231\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.1646 - val_loss: 0.3166\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.1589 - val_loss: 0.3115\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.1532 - val_loss: 0.3078\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1477 - val_loss: 0.3044\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1426 - val_loss: 0.2994\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1382 - val_loss: 0.2933\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1336 - val_loss: 0.2906\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.1292 - val_loss: 0.2893\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1253 - val_loss: 0.2863\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1216 - val_loss: 0.2841\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.1180 - val_loss: 0.2842\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.1144 - val_loss: 0.2831\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.1111 - val_loss: 0.2814\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1078 - val_loss: 0.2817\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1044 - val_loss: 0.2796\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.1012 - val_loss: 0.2763\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0983 - val_loss: 0.2737\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0953 - val_loss: 0.2716\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0927 - val_loss: 0.2697\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0900 - val_loss: 0.2685\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0872 - val_loss: 0.2674\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0845 - val_loss: 0.2683\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0820 - val_loss: 0.2698\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0797 - val_loss: 0.2677\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0775 - val_loss: 0.2654\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0755 - val_loss: 0.2654\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0734 - val_loss: 0.2646\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0715 - val_loss: 0.2618\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0695 - val_loss: 0.2597\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0675 - val_loss: 0.2583\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0657 - val_loss: 0.2562\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0640 - val_loss: 0.2532\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0623 - val_loss: 0.2494\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0606 - val_loss: 0.2476\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0591 - val_loss: 0.2475\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0577 - val_loss: 0.2464\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0563 - val_loss: 0.2468\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0548 - val_loss: 0.2480\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0534 - val_loss: 0.2497\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0521 - val_loss: 0.2515\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0507 - val_loss: 0.2512\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0495 - val_loss: 0.2520\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0482 - val_loss: 0.2516\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0469 - val_loss: 0.2500\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0456 - val_loss: 0.2506\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0443 - val_loss: 0.2512\n",
            "(330,)\n",
            "[10 10 10 10  9 10 10  9 10 10 10  2 10 10 10 10 10 10 10 10  9 10 10 10\n",
            " 10 10 10 10 10 10 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2\n",
            "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
            "  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
            "  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
            "  4  4  4  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5\n",
            "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  4  7  7  7  7  7  7  7  7  7  7  6  6  6  7  7  7  6  6  6  7  7  7  7\n",
            "  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
            "  8  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9\n",
            "  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geSfYq-NQc0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "91b51190-7c49-460e-ac8c-d930544319f8"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnO_ceVlR4lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00e81ec7-75e3-4776-97d0-5da324730f2e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test,predicted))"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9393939393939394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9xsmU2caE9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}